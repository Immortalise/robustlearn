coslr: false
coslrwarmup: true
criterions:
  PerformanceLoss:
    def_file: ./loss/GRWLoss.py
    loss_params: {exp_scale: 1.2, num_classes: 100, freq_path: ./cls_freq/CIFAR-100-LT_IMBA200.json}
    optim_params: null
    weight: 1.0
#criterions:
#  PerformanceLoss:
#    def_file: ./loss/SoftmaxLoss.py
#    loss_params: {}
#    optim_params: null
#    weight: 1.0
endlr: 0.0
warmup_iterations: 800
base_lr: 0.05
warmup_lr: 0.1
memory: {centroids: false, init_centroids: false}
model_dir: ./logs/CIFAR100_LT/models/resnet32_softmax_imba200 
networks:
networks:
  classifier:
    def_file: ./models/MARCClassifier.py
    optim_params: {lr: 0.05, momentum: 0.9, weight_decay: 0.0005}
    params: {feat_dim: 64,num_classes: 100, stage1_weights: True, cls_freq: ./cls_freq/CIFAR-100-LT_IMBA200.json, model_dir: ./logs/CIFAR100_LT/models/resnet32_softmax_imba200}
  feat_model:
    def_file: ./models/ResNet32Feature.py
    fix: True
    optim_params: {lr: 0.05, momentum: 0.9, weight_decay: 0.0005}
    params: {}
shuffle: false
training_opt:
  backbone: resnet32
  batch_size: 512
  dataset: CIFAR100_LT
  display_step: 10
  feature_dim: 64
  log_dir: ./logs/CIFAR100_LT/models/MARC_200
  num_classes: 100
  num_iterations: 2000
  num_workers: 4
  open_threshold: 0.1
  #sampler: {def_file: ./data/ClassAwareSampler.py, num_samples_cls: 4, type: ClassAwareSampler}
  sampler: null
  scheduler_params: {gamma: 0.1, step_size: 3}
  sub_dir: models
  cifar_imb_ratio: 200
